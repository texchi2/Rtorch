---
title: "Weakly supervised WSI classification model"
format: html
---

## Quarto with Pytorch

Here is a Python script that describes the training process for a weakly supervised whole-slide image (WSI) classification model based on the information you provided:

```{python}
import torch
from torch import nn, optim
from torchvision import models

# Set the device to run on
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Load the pretrained inception-ResNet-v2 model
model = models.inception_v3(pretrained=True)

# Replace the last layer with a custom layer for our specific task
num_classes = 2 # number of classes in our dataset
model.fc = nn.Linear(model.fc.in_features, num_classes)

# Move the model to the device
model.to(device)

# Set the loss function
criterion = nn.CrossEntropyLoss()

# Set the optimizer
optimizer = optim.Adam(model.parameters(), lr=0.0002, weight_decay=1e-5)

# Set the batch size
batch_size = 299

# Set the number of validation epochs before early stopping
early_stopping_epochs = 20

# Set the number of patches before checkpointing
checkpoint_patches = 100000

# Initialize variables for early stopping and checkpointing
best_val_loss = float("inf")
val_loss_increases = 0

for epoch in range(num_epochs):
    # Train the model on the training dataset
    model.train()
    for i, (inputs, labels) in enumerate(train_dataloader):
        # Move the inputs and labels to the device
        inputs, labels = inputs.to(device), labels.to(device)
        
        # Zero the gradients
        optimizer.zero_grad()
        
        # Forward pass
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        
        # Backward pass and optimization step
        loss.backward()
        optimizer.step()
        
        # Checkpoint the model every checkpoint_patches patches
        if (i + 1) % checkpoint_patches == 0:
            # Evaluate the model on the validation dataset
            model.eval()
            with torch.no_grad():
                val_loss = 0.0
                for val_inputs, val_labels in val_dataloader:
                    # Move the inputs and labels to the device
                    val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)
                    
                    # Forward pass
                    val_outputs = model(val_inputs)
                    val_loss += criterion(val_outputs, val_labels).item()
            
            # Calculate the average validation loss
            val_loss /= len(val_dataloader)
            
            # Check for early stopping
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                val_loss_increases = 0
                
                # Save the best model so far
                torch.save(model.state_dict(), "best_model.pth")
            else:
                val_loss_increases += 1
                
                if val_loss_increases >= early_stopping_epochs:
                    print("Early stopping")
                    break
    
    if val_loss_increases >= early_stopping_epochs:
        break

# Load the best model for evaluation on the test set
model.load_state_dict(torch.load("best_model.pth"))

```

This script assumes that you have already loaded your data into `train_dataloader` and `val_dataloader` using PyTorch's `DataLoader` class. 
You will also need to set `num_epochs` to the desired number of training epochs.

Please note that this script is just a starting point and may require further modifications and fine-tuning to fit your specific needs.

```{r}
#| echo: false
2 * 2
```

The `echo: false` option disables the printing of code (only output is displayed).
